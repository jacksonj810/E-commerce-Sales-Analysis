{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1667,
   "id": "a1b90ec7-9c41-4ae9-b1ec-699a7dc19c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1668,
   "id": "2d87d745-fa55-418e-887c-f3d47540884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloud_comp = pd.read_csv('cloud.csv')\n",
    "df_sale = pd.read_csv('sale.csv')\n",
    "df_march = pd.read_csv('march.csv')\n",
    "df_may = pd.read_csv('may.csv')\n",
    "df_amazon_sale = pd.read_csv('amazon.csv', low_memory = False)\n",
    "df_international = pd.read_csv('international.csv')\n",
    "df_expense = pd.read_csv('expense.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1669,
   "id": "750378cb-c048-4ad6-8cd1-ce0ebb1a12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df_amazon_sale = df_amazon_sale.drop(columns=[\n",
    "    'Courier Status',\n",
    "    'Unnamed: 22',\n",
    "    'ASIN',\n",
    "    'promotion-ids',\n",
    "    'ship-postal-code',\n",
    "    'index'\n",
    "])\n",
    "\n",
    "# Calculate mean of Amount\n",
    "mean_amount = df_amazon_sale['Amount'].mean()\n",
    "\n",
    "# Fill missing values\n",
    "df_amazon_sale = df_amazon_sale.fillna({\n",
    "    'currency': 'Unknown',\n",
    "    'ship-city': 'Unknown',\n",
    "    'ship-state': 'Unknown',\n",
    "    'ship-country': 'Unknown',\n",
    "    'fulfilled-by': 'Unknown',\n",
    "    'Amount': mean_amount\n",
    "})\n",
    "\n",
    "# Remove duplicates\n",
    "df_amazon_sale = df_amazon_sale.drop_duplicates()\n",
    "\n",
    "# Convert values to correct types\n",
    "    # Convert 'Date' to datetime\n",
    "df_amazon_sale['Date'] = pd.to_datetime(\n",
    "    df_amazon_sale['Date'], \n",
    "    format='%m-%d-%y',  # Adjust if your date format differs\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Check 'Qty' is numeric (integer)\n",
    "df_amazon_sale['Qty'] = pd.to_numeric(df_amazon_sale['Qty'], errors='coerce') \\\n",
    "                              .astype('Int64') \n",
    "\n",
    "# Check 'Amount' is numeric (float)\n",
    "df_amazon_sale['Amount'] = pd.to_numeric(df_amazon_sale['Amount'], errors='coerce')\n",
    "\n",
    "# Check 'B2B' is boolean\n",
    "df_amazon_sale['B2B'] = df_amazon_sale['B2B'].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1670,
   "id": "28c05aed-c6fd-4866-8daf-35098c6dbb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV\n",
    "df_cloud_comp = pd.read_csv('cloud.csv')\n",
    "\n",
    "# Keep only rows 1-4 where numerical cost is\n",
    "df_cloud_comp = df_cloud_comp.iloc[1:5].copy()\n",
    "\n",
    "# Rename columns:\n",
    "df_cloud_comp.rename(\n",
    "    columns={\n",
    "        'Shiprocket': 'Description',\n",
    "        'Unnamed: 1': 'Shiprocket'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Drop columns not needed\n",
    "df_cloud_comp.drop(columns=['index', 'Description'], errors='ignore', inplace=True)\n",
    "\n",
    "# Clean and convert new 'Shiprocket' column to numeric\n",
    "df_cloud_comp['Shiprocket'] = (\n",
    "    df_cloud_comp['Shiprocket']\n",
    "    .astype(str)\n",
    "    .str.replace('â‚¹', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .str.extract(r'(\\d+(?:\\.\\d+)?)')  # extract only the number pattern\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Clean and convert 'INCREFF' to numeric\n",
    "df_cloud_comp['INCREFF'] = (\n",
    "    df_cloud_comp['INCREFF']\n",
    "    .astype(str)\n",
    "    .str.replace('Rs', '', regex=False)\n",
    "    .str.replace('/- Per Day', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .str.extract(r'(\\d+(?:\\.\\d+)?)')\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Fill NaNs with 0.0\n",
    "df_cloud_comp = df_cloud_comp.fillna({'Shiprocket': 0.0, 'INCREFF': 0.0})\n",
    "\n",
    "# Remove duplicates if any\n",
    "df_cloud_comp = df_cloud_comp.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1671,
   "id": "4c13d375-c5e9-486a-8623-f1e19442d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean international\n",
    "\n",
    "# Read international csv\n",
    "df_international = pd.read_csv('international.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_international = df_international.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "# Convert 'DATE' to datetime\n",
    "df_international['DATE'] = pd.to_datetime(\n",
    "    df_international['DATE'],\n",
    "    errors='coerce',\n",
    "    format='%m-%d-%y'  \n",
    ")\n",
    "\n",
    "# Convert numeric columns (PCS, RATE, GROSS AMT) from string/object to numeric (invalid becomes NaN for later filling)\n",
    "df_international['PCS'] = pd.to_numeric(df_international['PCS'], errors='coerce')\n",
    "df_international['RATE'] = pd.to_numeric(df_international['RATE'], errors='coerce')\n",
    "df_international['GROSS AMT'] = pd.to_numeric(df_international['GROSS AMT'], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "    # For numeric columns (PCS, RATE, GROSS AMT) fill with 0\n",
    "    # For text columns (Style, SKU, Size, Months, CUSTOMER) fill with 'Unknown'\n",
    "df_international = df_international.fillna({\n",
    "    'Style': 'Unknown',\n",
    "    'SKU': 'Unknown',\n",
    "    'Size': 'Unknown',\n",
    "    'Months': 'Unknown',\n",
    "    'CUSTOMER': 'Unknown',\n",
    "    'PCS': 0,\n",
    "    'RATE': 0.0,\n",
    "    'GROSS AMT': 0.0\n",
    "})\n",
    "\n",
    "# Convert PCS to integer\n",
    "df_international['PCS'] = df_international['PCS'].astype(int)\n",
    "\n",
    "# Remove duplicates if any\n",
    "df_international = df_international.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1672,
   "id": "3e510624-ad65-4618-96c7-7e92fe2caac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean expense\n",
    "\n",
    "# Read csv\n",
    "df_expense = pd.read_csv('expense.csv')\n",
    "\n",
    "# Drop the first row (extra headers)\n",
    "df_expense = df_expense.iloc[1:].copy()\n",
    "\n",
    "# Drop index (pandas already has its own index)\n",
    "df_expense = df_expense.drop(columns=['index'])\n",
    "\n",
    "\n",
    "# Rename columns\n",
    "df_expense = df_expense.rename(\n",
    "    columns={\n",
    "        'Recived Amount': 'Date',\n",
    "        'Unnamed: 1': 'Received_Amount',\n",
    "        'Expance': 'ExpenseDesc',\n",
    "        'Unnamed: 3': 'ExpenseAmount'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Remove row that says 'Total' in the Date column (row 16)\n",
    "df_expense = df_expense[df_expense['Date'] != 'Total']\n",
    "\n",
    "# Convert Date to datetime\n",
    "df_expense['Date'] = pd.to_datetime(\n",
    "    df_expense['Date'],\n",
    "    errors='coerce',      # invalid formats become NaT\n",
    "    format='%m-%d-%y'     # update if your date format differs\n",
    ")\n",
    "\n",
    "# Convert numeric columns\n",
    "df_expense['Received_Amount'] = pd.to_numeric(\n",
    "    df_expense['Received_Amount'], errors='coerce'\n",
    ")\n",
    "df_expense['ExpenseAmount'] = pd.to_numeric(\n",
    "    df_expense['ExpenseAmount'], errors='coerce'\n",
    ")\n",
    "\n",
    "# Fill missing numeric values with 0\n",
    "df_expense['Received_Amount'] = df_expense['Received_Amount'].fillna(0)\n",
    "df_expense['ExpenseAmount'] = df_expense['ExpenseAmount'].fillna(0)\n",
    "\n",
    "# Remove duplicates if any\n",
    "df_expense = df_expense.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1673,
   "id": "fd2cb443-3e92-4d0c-bd8e-6fc391141196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean may\n",
    "\n",
    "# Read csv\n",
    "df_may = pd.read_csv('may.csv')\n",
    "\n",
    "# Drop columns (index)\n",
    "df_may = df_may.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "# Convert needed columns to numeric\n",
    "numeric_cols = [\n",
    "    'Weight',\n",
    "    'MRP Old',\n",
    "    'Final MRP Old',\n",
    "    'Ajio MRP',\n",
    "    'Amazon MRP',\n",
    "    'Amazon FBA MRP',\n",
    "    'Flipkart MRP',\n",
    "    'Limeroad MRP',\n",
    "    'Myntra MRP',\n",
    "    'Paytm MRP',\n",
    "    'Snapdeal MRP',\n",
    "    'TP'\n",
    "]\n",
    "\n",
    "# Convert each column in numeric_cols to numeric\n",
    "for col in numeric_cols:\n",
    "    if col in df_may.columns:\n",
    "        df_may[col] = pd.to_numeric(df_may[col], errors='coerce')\n",
    "\n",
    "# Fill missing values:\n",
    "    # Numeric columns = 0\n",
    "    # String columns = 'Unknown'\n",
    "string_cols = ['Sku', 'Catalog', 'Category']  \n",
    "\n",
    "# Fill numeric columns with 0\n",
    "df_may[numeric_cols] = df_may[numeric_cols].fillna(0)\n",
    "\n",
    "# Fill string columns with 'Unknown'\n",
    "for col in string_cols:\n",
    "    if col in df_may.columns:\n",
    "        df_may[col] = df_may[col].fillna('Unknown')\n",
    "\n",
    "# Remove duplicates if any\n",
    "df_may = df_may.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1674,
   "id": "7c345b61-085a-487f-a626-39e6d3775ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean march\n",
    "\n",
    "# Read csv\n",
    "df_march = pd.read_csv('march.csv')\n",
    "\n",
    "# Drop columns (index)\n",
    "df_march = df_march.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "# Convert relevant columns to numeric\n",
    "numeric_cols = [\n",
    "    'Weight',\n",
    "    'MRP Old',\n",
    "    'Final MRP Old',\n",
    "    'Ajio MRP',\n",
    "    'Amazon MRP',\n",
    "    'Amazon FBA MRP',\n",
    "    'Flipkart MRP',\n",
    "    'Limeroad MRP',\n",
    "    'Myntra MRP',\n",
    "    'Paytm MRP',\n",
    "    'Snapdeal MRP',\n",
    "    'TP 1',\n",
    "    'TP 2',\n",
    "]\n",
    "\n",
    "# Convert each column in numeric_cols to numeric\n",
    "for col in numeric_cols:\n",
    "    if col in df_march.columns:\n",
    "        df_march[col] = pd.to_numeric(df_march[col], errors='coerce')\n",
    "\n",
    "# Fill missing values:\n",
    "    # Numeric columns = 0\n",
    "    # String columns = 'Unknown'\n",
    "string_cols = ['Sku', 'Catalog', 'Category'] \n",
    "\n",
    "# Fill numeric columns with 0\n",
    "df_march[numeric_cols] = df_march[numeric_cols].fillna(0)\n",
    "\n",
    "# Fill string columns with 'Unknown'\n",
    "for col in string_cols:\n",
    "    if col in df_march.columns:\n",
    "        df_march[col] = df_march[col].fillna('Unknown')\n",
    "\n",
    "# Remove duplicates if any\n",
    "df_march = df_march.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1675,
   "id": "ee071a5e-f899-49e1-a8e7-f34e98a9b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean sale\n",
    "\n",
    "# Read csv\n",
    "df_sale = pd.read_csv('sale.csv')\n",
    "\n",
    "# Drop columns (index)\n",
    "df_sale = df_sale.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "\n",
    "# Convert 'Stock' to numeric\n",
    "df_sale['Stock'] = pd.to_numeric(df_sale['Stock'], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "    # 'Stock' (numeric) = 0\n",
    "    # String columns = 'Unknown'\n",
    "string_cols = ['SKU Code', 'Design No.', 'Category', 'Size', 'Color']\n",
    "\n",
    "df_sale['Stock'] = df_sale['Stock'].fillna(0)\n",
    "\n",
    "for col in string_cols:\n",
    "    if col in df_sale.columns:\n",
    "        df_sale[col] = df_sale[col].fillna('Unknown')\n",
    "\n",
    "# Remove duplicates\n",
    "df_sale = df_sale.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1676,
   "id": "f9df0b0c-ce51-476f-8416-3dfdfc0fc87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PCS</th>\n",
       "      <th>RATE</th>\n",
       "      <th>GROSS AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12322</td>\n",
       "      <td>23887.000000</td>\n",
       "      <td>23887.000000</td>\n",
       "      <td>23887.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021-11-22 11:36:30.618406144</td>\n",
       "      <td>366.952736</td>\n",
       "      <td>812.732836</td>\n",
       "      <td>470.148876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2021-06-05 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-09-11 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>462.500000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2021-11-03 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>353.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022-02-24 00:00:00</td>\n",
       "      <td>562.000000</td>\n",
       "      <td>925.000000</td>\n",
       "      <td>688.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-05-11 00:00:00</td>\n",
       "      <td>57400.000000</td>\n",
       "      <td>57400.000000</td>\n",
       "      <td>9745.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>880.992478</td>\n",
       "      <td>917.042063</td>\n",
       "      <td>638.411231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DATE           PCS          RATE     GROSS AMT\n",
       "count                          12322  23887.000000  23887.000000  23887.000000\n",
       "mean   2021-11-22 11:36:30.618406144    366.952736    812.732836    470.148876\n",
       "min              2021-06-05 00:00:00      0.000000      0.000000      0.000000\n",
       "25%              2021-09-11 00:00:00      1.000000    462.500000     10.000000\n",
       "50%              2021-11-03 00:00:00      3.000000    628.000000    353.000000\n",
       "75%              2022-02-24 00:00:00    562.000000    925.000000    688.000000\n",
       "max              2022-05-11 00:00:00  57400.000000  57400.000000   9745.000000\n",
       "std                              NaN    880.992478    917.042063    638.411231"
      ]
     },
     "execution_count": 1676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numeric Summaries\n",
    "df_amazon_sale.describe()\n",
    "df_cloud_comp.describe()\n",
    "df_may.describe()\n",
    "df_march.describe()\n",
    "df_sale.describe()\n",
    "df_expense.describe()\n",
    "df_international.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1677,
   "id": "5fdaeb76-c2cc-4971-a849-f717b810b9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Sales:\n",
      "   Year  Month        Amount\n",
      "0  2022      3  1.075209e+05\n",
      "1  2022      4  3.078245e+07\n",
      "2  2022      5  2.784835e+07\n",
      "3  2022      6  2.490531e+07\n",
      "Category Sales (Descending):\n",
      "        Category        Amount\n",
      "5            Set  4.130401e+07\n",
      "8          kurta  2.334717e+07\n",
      "7  Western Dress  1.173233e+07\n",
      "6            Top  5.644185e+06\n",
      "3   Ethnic Dress  8.340227e+05\n",
      "Currency Counts:\n",
      "currency\n",
      "INR        121177\n",
      "Unknown      7792\n",
      "Name: count, dtype: int64\n",
      "Stock Summary:\n",
      "count    9233.000000\n",
      "mean       26.252139\n",
      "std        58.467946\n",
      "min         0.000000\n",
      "25%         3.000000\n",
      "50%         8.000000\n",
      "75%        31.000000\n",
      "max      1234.000000\n",
      "Name: Stock, dtype: float64\n",
      "Items with <10 in Stock:\n",
      "        SKU Code Design No.  Stock       Category Size Color\n",
      "0    AN201-RED-L      AN201    5.0  AN : LEGGINGS    L   Red\n",
      "1    AN201-RED-M      AN201    5.0  AN : LEGGINGS    M   Red\n",
      "2    AN201-RED-S      AN201    3.0  AN : LEGGINGS    S   Red\n",
      "3   AN201-RED-XL      AN201    6.0  AN : LEGGINGS   XL   Red\n",
      "4  AN201-RED-XXL      AN201    3.0  AN : LEGGINGS  XXL   Red\n"
     ]
    }
   ],
   "source": [
    "# Analyze general sales trends\n",
    "\n",
    "# Make 'Date' a datetime\n",
    "df_amazon_sale['Month'] = df_amazon_sale['Date'].dt.month\n",
    "df_amazon_sale['Year'] = df_amazon_sale['Date'].dt.year\n",
    "\n",
    "# Group by Year and Month to see total Amount\n",
    "monthly_sales = df_amazon_sale.groupby(['Year', 'Month'], as_index=False)['Amount'].sum()\n",
    "\n",
    "print('Monthly Sales:')\n",
    "print(monthly_sales.head())\n",
    "\n",
    "# Sales by different category\n",
    "category_sales = df_amazon_sale.groupby('Category', as_index=False)['Amount'].sum()\n",
    "category_sales.sort_values('Amount', ascending=False, inplace=True)\n",
    "\n",
    "print('Category Sales (Descending):')\n",
    "print(category_sales.head())\n",
    "\n",
    "# Currency and stock level \n",
    "print('Currency Counts:')\n",
    "print(df_amazon_sale['currency'].value_counts())\n",
    "\n",
    "# Stock level stats\n",
    "print('Stock Summary:')\n",
    "print(df_sale['Stock'].describe())\n",
    "\n",
    "# Filter low-stock items\n",
    "low_stock_items = df_sale[df_sale['Stock'] < 10]\n",
    "print('Items with <10 in Stock:')\n",
    "print(low_stock_items.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1679,
   "id": "5a6c8c96-5332-4098-abe6-54b4ff903b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export new data to csv for Tableau\n",
    "\n",
    "# Amazon Sale Report\n",
    "df_amazon_sale.to_csv('amazon_sale_cleaned.csv', index=False)\n",
    "\n",
    "# Cloud Warehouse Comparison Chart\n",
    "df_cloud_comp.to_csv('cloud_comp_cleaned.csv', index=False)\n",
    "\n",
    "# Expense IIGF\n",
    "df_expense.to_csv('expense_cleaned.csv', index=False)\n",
    "\n",
    "# International Sale Report\n",
    "df_international.to_csv('international_cleaned.csv', index=False)\n",
    "\n",
    "# May 2022\n",
    "df_may.to_csv('may_cleaned.csv', index=False)\n",
    "\n",
    "# March 2021\n",
    "df_march.to_csv('march_cleaned.csv', index=False)\n",
    "\n",
    "# Sale Report\n",
    "df_sale.to_csv('sale_cleaned.csv', index=False)\n",
    "\n",
    "# Additional Summary DataFrames\n",
    "monthly_sales.to_csv('monthly_sales.csv', index=False)\n",
    "category_sales.to_csv('category_sales.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "id": "6ef4a1dc-f845-41f7-9019-c9cf231c5a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel MRP Statistics:\n",
      "       Amazon FBA MRP   Myntra MRP     Ajio MRP  Flipkart MRP    Paytm MRP  \\\n",
      "count     1330.000000  1330.000000  1330.000000   1330.000000  1330.000000   \n",
      "mean      2185.256729  2180.483045  2178.913120   2180.717632  2176.215376   \n",
      "std        786.556700   763.422217   789.392891    787.270554   784.746164   \n",
      "min          0.000000     0.000000     0.000000      0.000000     0.000000   \n",
      "25%       1795.000000  1795.000000  1695.000000   1695.000000  1795.000000   \n",
      "50%       2095.000000  2095.000000  2050.000000   2095.000000  2050.000000   \n",
      "75%       2495.000000  2494.000000  2494.000000   2494.000000  2494.000000   \n",
      "max       5997.000000  5997.000000  5997.000000   5997.000000  5997.000000   \n",
      "\n",
      "       Snapdeal MRP  \n",
      "count   1330.000000  \n",
      "mean    2177.418383  \n",
      "std      785.013724  \n",
      "min        0.000000  \n",
      "25%     1695.000000  \n",
      "50%     2095.000000  \n",
      "75%     2494.000000  \n",
      "max     5997.000000  \n",
      "Average MRP by Channel (Descending):\n",
      "Amazon FBA MRP    2185.256729\n",
      "Flipkart MRP      2180.717632\n",
      "Myntra MRP        2180.483045\n",
      "Ajio MRP          2178.913120\n",
      "Snapdeal MRP      2177.418383\n",
      "Paytm MRP         2176.215376\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compare Prices Across Channels\n",
    "\n",
    "# Descriptive analysis\n",
    "channel_cols = ['Amazon FBA MRP', 'Myntra MRP', 'Ajio MRP', \n",
    "                'Flipkart MRP', 'Paytm MRP', 'Snapdeal MRP']\n",
    "channel_stats = df_may[channel_cols].describe()\n",
    "print('Channel MRP Statistics:')\n",
    "print(channel_stats)\n",
    "\n",
    "# Identify Which Channel Has Highest/Lowest Prices\n",
    "avg_mrp = df_may[channel_cols].mean().sort_values(ascending=False)\n",
    "print('Average MRP by Channel (Descending):')\n",
    "print(avg_mrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1681,
   "id": "418a497e-3797-4420-8800-253bf7ca6690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross Amount by SKU & Customer:\n",
      "           SKU                         CUSTOMER  GROSS AMT\n",
      "19742  Unknown              MULBERRIES BOUTIQUE   380453.5\n",
      "19721  Unknown          BHANU SALEINE NAUNITHAM    71675.0\n",
      "19736  Unknown                Jeannie Thein Win    71400.0\n",
      "19730  Unknown                     Diya Designs    69270.0\n",
      "19732  Unknown  Fusion Fashions Corp. (Gopikas)    67840.0\n",
      "19734  Unknown                          Gajanan    59887.5\n",
      "19725  Unknown                   Chaaya Sookdeb    54725.0\n",
      "19747  Unknown                   Priyanka Gupta    53260.0\n",
      "19761  Unknown                  The Pink Market    37890.0\n",
      "19745  Unknown                        Natheliya    35675.0\n",
      "19746  Unknown        Nitha Pushpangadan Sarala    32300.0\n",
      "19753  Unknown                    Rino Sandaran    30347.5\n",
      "19752  Unknown                      Ria Fashion    29735.1\n",
      "19763  Unknown            Valli Arangan Fashion    29162.5\n",
      "19755  Unknown                             Siva    27199.0\n",
      "SKU Performance Over Time:\n",
      "                SKU    Year  Month  GROSS AMT\n",
      "0    AN202-ORANGE-L  2021.0    8.0      281.0\n",
      "1    AN202-ORANGE-M  2021.0    8.0      281.0\n",
      "2    AN202-ORANGE-S  2021.0    8.0      281.0\n",
      "3   AN202-ORANGE-XL  2021.0    8.0      281.0\n",
      "4  AN202-ORANGE-XXL  2021.0    8.0      281.0\n",
      "5    AN204-PURPLE-M  2021.0    7.0      281.0\n",
      "6    AN205-YELLOW-L  2021.0    8.0      281.0\n",
      "7    AN205-YELLOW-M  2021.0    8.0      281.0\n",
      "8    AN205-YELLOW-S  2021.0    8.0      281.0\n",
      "9   AN209-BIEGE-XXL  2021.0    7.0      281.0\n"
     ]
    }
   ],
   "source": [
    "# Customer-Specific Data \n",
    "\n",
    "# Group by SKU & CUSTOMER to see total GROSS AMT\n",
    "sku_customer_sales = df_international.groupby(['SKU','CUSTOMER'], as_index=False)['GROSS AMT'].sum()\n",
    "sku_customer_sales.sort_values('GROSS AMT', ascending=False, inplace=True)\n",
    "print('Gross Amount by SKU & Customer:')\n",
    "print(sku_customer_sales.head(15))\n",
    "\n",
    "# Analyzing over time\n",
    "df_international['Year'] = df_international['DATE'].dt.year\n",
    "df_international['Month'] = df_international['DATE'].dt.month\n",
    "\n",
    "# sum GROSS AMT monthly per SKU\n",
    "sku_monthly = df_international.groupby(['SKU','Year','Month'], as_index=False)['GROSS AMT'].sum()\n",
    "print('SKU Performance Over Time:')\n",
    "print(sku_monthly.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "id": "19fe1c52-3867-48b8-bfc4-64ff53d982b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Received: 5000.0\n",
      "Total Expenses: 13095\n",
      "Net Balance: -8095.0\n",
      "Merged Stock & P&L Data:\n",
      "        SKU Code  Stock  Sku Style Id Catalog Category  Weight  TP 1  TP 2  \\\n",
      "0    AN201-RED-L    5.0  NaN      NaN     NaN      NaN     NaN   NaN   NaN   \n",
      "1    AN201-RED-M    5.0  NaN      NaN     NaN      NaN     NaN   NaN   NaN   \n",
      "2    AN201-RED-S    3.0  NaN      NaN     NaN      NaN     NaN   NaN   NaN   \n",
      "3   AN201-RED-XL    6.0  NaN      NaN     NaN      NaN     NaN   NaN   NaN   \n",
      "4  AN201-RED-XXL    3.0  NaN      NaN     NaN      NaN     NaN   NaN   NaN   \n",
      "\n",
      "   MRP Old  Final MRP Old  Ajio MRP  Amazon MRP  Amazon FBA MRP  Flipkart MRP  \\\n",
      "0      NaN            NaN       NaN         NaN             NaN           NaN   \n",
      "1      NaN            NaN       NaN         NaN             NaN           NaN   \n",
      "2      NaN            NaN       NaN         NaN             NaN           NaN   \n",
      "3      NaN            NaN       NaN         NaN             NaN           NaN   \n",
      "4      NaN            NaN       NaN         NaN             NaN           NaN   \n",
      "\n",
      "   Limeroad MRP  Myntra MRP  Paytm MRP  Snapdeal MRP  \n",
      "0           NaN         NaN        NaN           NaN  \n",
      "1           NaN         NaN        NaN           NaN  \n",
      "2           NaN         NaN        NaN           NaN  \n",
      "3           NaN         NaN        NaN           NaN  \n",
      "4           NaN         NaN        NaN           NaN  \n",
      "SKUs with leftover > 50:\n",
      "         SKU Code  Stock            SKU  Qty  Leftover\n",
      "61  BL003-50BLACK  117.0  BL003-50BLACK    2     115.0\n",
      "64  BL006-54BLACK  112.0  BL006-54BLACK    6     106.0\n",
      "66   BL007-61PINK   56.0            NaN    0      56.0\n",
      "69  BL009-61BLACK  575.0  BL009-61BLACK    5     570.0\n",
      "70  BL010-61CHIKU   75.0            NaN    0      75.0\n"
     ]
    }
   ],
   "source": [
    "# Overall Stock + Expenses for Cost-Cutting Trends \n",
    "\n",
    "# Summarize expenses\n",
    "total_received = df_expense['Received_Amount'].sum()\n",
    "total_expense = df_expense['ExpenseAmount'].sum()\n",
    "net_balance = total_received - total_expense\n",
    "\n",
    "print('Total Received:', total_received)\n",
    "print('Total Expenses:', total_expense)\n",
    "print('Net Balance:', net_balance)\n",
    "\n",
    "# Merge Stock with Sales or P&L\n",
    "df_stock_pl = pd.merge(\n",
    "    df_sale[['SKU Code','Stock']],\n",
    "    df_march,         \n",
    "    left_on='SKU Code',\n",
    "    right_on='Sku',          \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print('Merged Stock & P&L Data:')\n",
    "print(df_stock_pl.head())\n",
    "\n",
    "# Identify High Stock, Low Turnover\n",
    "df_merged_stock_sales = pd.merge(\n",
    "    df_sale[['SKU Code','Stock']],\n",
    "    df_amazon_sale.groupby('SKU', as_index=False)['Qty'].sum(), \n",
    "    left_on='SKU Code',\n",
    "    right_on='SKU',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_merged_stock_sales['Qty'] = df_merged_stock_sales['Qty'].fillna(0)\n",
    "\n",
    "# Stock turnover ratio or leftover stock\n",
    "df_merged_stock_sales['Leftover'] = df_merged_stock_sales['Stock'] - df_merged_stock_sales['Qty']\n",
    "\n",
    "high_leftover = df_merged_stock_sales[df_merged_stock_sales['Leftover'] > 50]\n",
    "print('SKUs with leftover > 50:')\n",
    "print(high_leftover.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "id": "b68af0fc-329f-4292-957a-841d324d5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by SKU, Customer, and Date\n",
    "sku_customer_summary = df_amazon_sale.groupby(['SKU', 'Order ID', 'Date']).agg({\n",
    "    'Amount': 'sum',  \n",
    "    'Qty': 'sum'  \n",
    "}).reset_index()\n",
    "\n",
    "# Save to CSV\n",
    "sku_customer_summary.to_csv('sku_customer_summary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "id": "e3e11c2b-06db-48ba-b936-9befccd75bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stock and sales data\n",
    "category_stock_sales = df_sale.merge(\n",
    "    df_amazon_sale, on='Category', how='inner'\n",
    ")\n",
    "\n",
    "# Group by category\n",
    "category_analysis = category_stock_sales.groupby('Category').agg({\n",
    "    'Stock': 'sum',      \n",
    "    'Amount': 'sum'     \n",
    "}).reset_index()\n",
    "\n",
    "# Calculate Stock-to-Sales Ratio\n",
    "category_analysis['Stock-to-Sales Ratio'] = category_analysis['Stock'] / category_analysis['Amount']\n",
    "\n",
    "# Save to CSV for Tableau\n",
    "category_analysis.to_csv('category_stock_sales.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "id": "947e838b-6496-49f7-843a-69840c4d7897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique categories in df_salet:\n",
      "['AN : LEGGINGS' 'BLOUSE' 'PANT' 'BOTTOM' 'PALAZZO' 'SHARARA' 'SKIRT'\n",
      " 'DRESS' 'KURTA SET' 'LEHENGA CHOLI' 'SET' 'TOP' 'KURTA' 'Unknown'\n",
      " 'CROP TOP' 'TUNIC' 'CARDIGAN' 'JUMPSUIT' 'CROP TOP WITH PLAZZO' 'SAREE'\n",
      " 'KURTI' 'NIGHT WEAR']\n",
      "\n",
      "Unique categories in df_amazon_sale:\n",
      "['Set' 'kurta' 'Western Dress' 'Top' 'Ethnic Dress' 'Bottom' 'Saree'\n",
      " 'Blouse' 'Dupatta']\n"
     ]
    }
   ],
   "source": [
    "# Display unique categories in both DataFrames\n",
    "print('Unique categories in df_salet:')\n",
    "print(df_sale['Category'].unique())\n",
    "\n",
    "print('\\nUnique categories in df_amazon_sale:')\n",
    "print(df_amazon_sale['Category'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "id": "eb003a88-505f-4bdf-90fd-726f98682545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date        Amount\n",
      "0 2022-03-31  1.075209e+05\n",
      "1 2022-04-01  9.355232e+05\n",
      "2 2022-04-02  9.773091e+05\n",
      "3 2022-04-03  1.075971e+06\n",
      "4 2022-04-04  9.410783e+05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure Date column is in datetime format\n",
    "df_amazon_sale['Date'] = pd.to_datetime(df_amazon_sale['Date'], errors='coerce')\n",
    "\n",
    "# Group by Date and calculate total sales\n",
    "sales_over_time = df_amazon_sale.groupby('Date')['Amount'].sum().reset_index()\n",
    "\n",
    "# Save aggregated data to a CSV for Tableau\n",
    "sales_over_time.to_csv('sales_over_time.csv', index=False)\n",
    "\n",
    "# Print first few rows to verify\n",
    "print(sales_over_time.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "id": "95b85967-79b6-41fd-ba5a-a2c85d711261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Sku    Style Id  Catalog Category  Weight     TP  MRP Old  \\\n",
      "0    Os206_3141_S  Os206_3141  Moments    Kurta     0.3  538.0   2178.0   \n",
      "1    Os206_3141_M  Os206_3141  Moments    Kurta     0.3  538.0   2178.0   \n",
      "2    Os206_3141_L  Os206_3141  Moments    Kurta     0.3  538.0   2178.0   \n",
      "3   Os206_3141_XL  Os206_3141  Moments    Kurta     0.3  538.0   2178.0   \n",
      "4  Os206_3141_2XL  Os206_3141  Moments    Kurta     0.3  538.0   2178.0   \n",
      "\n",
      "   Final MRP Old   Channel     MRP  \n",
      "0         2295.0  Ajio MRP  2295.0  \n",
      "1         2295.0  Ajio MRP  2295.0  \n",
      "2         2295.0  Ajio MRP  2295.0  \n",
      "3         2295.0  Ajio MRP  2295.0  \n",
      "4         2295.0  Ajio MRP  2295.0  \n"
     ]
    }
   ],
   "source": [
    "# Load cleaned May CSV\n",
    "df_may = pd.read_csv('may_cleaned.csv')\n",
    "\n",
    "# Pivot the MRP columns into 'Channel' and 'MRP' for analysis\n",
    "channel_data = df_may.melt(\n",
    "    id_vars=['Sku', 'Style Id', 'Catalog', 'Category', 'Weight', 'TP', 'MRP Old', 'Final MRP Old'],  # Columns to retain\n",
    "    value_vars=[\n",
    "        'Ajio MRP', 'Amazon MRP', 'Amazon FBA MRP', 'Flipkart MRP', \n",
    "        'Limeroad MRP', 'Myntra MRP', 'Paytm MRP', 'Snapdeal MRP'\n",
    "    ],  # Columns to pivot\n",
    "    var_name='Channel',   # New column for channel names\n",
    "    value_name='MRP'      # New column for the MRP values\n",
    ")\n",
    "\n",
    "# Save pivoted data to a CSV for Tableau\n",
    "channel_data.to_csv('channel_comparison.csv', index=False)\n",
    "\n",
    "# Preview first few rows to confirm\n",
    "print(channel_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c37df-df5d-4416-a566-fa96ac307c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e50a9-27f0-4002-82f0-1e3ef5c6ea0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83600947-ef92-48b7-9588-8e3f72c0281d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd65d0-a862-4185-9276-619b7d9ada73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438bc0f-cdc1-46a6-9a11-3f083f556d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2389c-0859-4d52-83d7-62f9b3c09bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620fbfd2-673d-47ea-99b4-9e338f785380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116af38c-83a7-4c3d-b9a2-141b3372dd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972780c-a5af-4e20-af06-449c94fcfebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4ac6f-13a7-4222-bf43-7030cb7ff411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48616a64-1ff0-4f53-be86-01dc1c058592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2e4c8-0a07-4773-8da1-94795df1aa90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4865718-60c0-4cf2-bc7e-95ffff097224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43035c29-feb2-4af5-9672-71b1a1397763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f5259-b416-486c-a1c7-91ce52461624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
